<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 

    <title>Tune Helper</title>

    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/earlyaccess/nanumbrushscript.css">

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <!-- Latest compiled JavaScript -->
    <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
  </head>
  
  <body>
    <nav class="navbar navbar-default" id="head-navbar">
      <div class="container-fluid">
        <div class="navbar-header">
          <a class="navbar-brand" href="#" ><b>Tune Helper</b></a>
        </div>
        <div>
          <ul class="nav navbar-nav">
            <li><a href="#Introduction">Introduction</a></li>
            <li><a href="#Method">Approaches</a></li>
            <li><a href="#Example">Examples</a></li>
            <li><a href="#ProgramStructure">Program Structure</a></li>
            <li><a href="#UserInterface">User Interface</a></li>
            <li><a href="#Conclusion">Conclusion</a></li>
            <li><a href="#RelatedWorks">Related Works</a></li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container">
      <img src="slogan.png" style="height: 450px;">

      <div class="jumbotron" style="background-color:white;">
        <p>
          Fianl project for Northwestern University <a href="http://www.cs.northwestern.edu/~pardo/courses/eecs352/">EECS 352</a>ï¼ŒInstructor Prof. Bryan Pardo.<br>
          Paper: <a href="">HERE IS THE URL OF ABSTRACT</a>
          <br>
          <br>
          Team member: <a href="mailto:zhechen2014@u.northwestern.edu">Zhe Chen</a>, <a href="mailto:chenxingwu2014@u.northwestern.edu">Chenxing Wu</a>, <a href="mailto:maxinchen2014@u.northwestern.edu">Maxin Chen</a>
          <br>
        </p> 
        <br>
        <button type="button" class="btn btn-info">View on GitHub</button>
      </div>

      <div class="jumbotron" id="Introduction">
        <h2>Introduction</h2>
        <hr>
        <h3>What is Tune Helper</h3>
        <p>
          Tune Helper is a program that can "Speech-to-sing", tuning human voice to sing a simple melody, or "Auto-tuning", creating perfectly tuned vocals by altering off-key pitches.
        </p>
        <p>
          It is written and built in MATLAB.
        </p>

        <h3>Motivation</h3>
        <p>
          Our final project Tune Helper is inspired by music software Auto-Tune, which can auto correlate vocals, creating a very cool electronic vocal effect. (See <a href="#RelatedWorks">Related Works</a> for details)
        </p>

        <h3>Goals and Process</h3>
        <p>
          We want to implement the basic function of Auto-Tune, pitch auto-correction, on MATLAB by ourselves. And we also want to create an interesting function, which uses human speech and a simple melody as input, after the audio processing procedure, combining human speech with melody, producing an audio which is a tuned human speech that its pitch is exactly matched to the input melody's.
        </p>
        <p>
          We use following audio processing methods to to achieve these functions:
          <br>

          - <b>Pitch tracking</b>: analyze input human voice and melody, obtaining their time and frequency information.
          <br>
          - <b>Beat tracking</b>: detect beat and match voice with input melody.
          <br>
          - <b>Phase vocoder</b>: time stretch and compress.
        </p>
        <p>Check out <a href="#Method">approaches</a> and <a href="#Example">examples</a> below to see how it works.</p>
        <a href="#head-navbar">Back to top</a>
      </div>
      
      <div class="jumbotron" id="Method">
        <h2>Approaches</h2>
        <hr>
        <p>
          We use primarily these three methods, pitch tracking, beat tracking and phase vocoder, to write the core functions of Tune Helper.
          <br>
        </p>
        <p>
          <b>Pitch Tracking</b>:<br>
          We use <a href="praat_pd.m">praat_pd.m</a> pitch tracker to extract the time, frequency and amplitude information from input audio.<br>
          Usage:
          <code>[frq_path, autoCorr_path, time, amp] = praat_pd(y,fs,0);</code>
          <br>
        </p>

        <p>
          <b>Beat Tracking</b>:<br>
          We use the method from paper: <a href="http://www.ee.columbia.edu/~dpwe/pubs/Ellis07-beattrack.pdf">Beat Tracking by Dynamic Programming</a>.
        </p>

        <p>
          <b>Phase Vocoder</b>:<br>
          Wiki:<a href="http://en.wikipedia.org/wiki/Phase_vocoder">http://en.wikipedia.org/wiki/Phase_vocoder</a><br>
          We use <a href="PV.m">PV.m</a> phase vocoder to perform time expansion, time compression and pitch shifting for audio clip.<br>
          Usage:
          <code>y=PV(x,fs,hopin,hopout);</code>
        </p>
        <br>
        <a href="#head-navbar">Back to top</a>
      </div>



      <div class="jumbotron" id="Example">
        <h2>Examples</h2>
        <hr>
        <p>
          Here are two examples to show and demonstrate the audio processing procedure of Tune Helper.<br>
        </p>

        <div id="Speech-to-song">
          <h3>1. Speech-to-sing</h3>
          <p>We use the famous nursery rhyme "Mary had a little lamb" as the input of Speech-to-sing.</p>
          <p>
            Human voice input: 
            <a href="sing_voice.mp3" class="btn btn-default btn-sm" role="button" target="blank">
              <span class="glyphicon glyphicon-play"></span>
            </a>
            <br>          

            Piano melody input: 
            <a href="sing_melody.mp3" class="btn btn-default btn-sm" role="button" target="blank">
              <span class="glyphicon glyphicon-play"></span>
            </a>
            <br>
            Output of Speech-to-sing: 
            <a href="sing_result.wav" class="btn btn-default btn-sm" role="button" target="blank">
              <span class="glyphicon glyphicon-play"></span>
            </a>
          </p>
          <p>
            Explaination:<br> 
            Tune Helper first uses beat tracking method to analyze both human voice input and piano melody input, extracting the time, frequency and amplitude information. It then uses phase vocoder to  shift the pitch of human voice input, according to the relative pitch height information of piano melody input extracted by pitch tracker. After the processing procedure, the result is a singing speech.<br>
            (Check out <a href="#ProgramStructure">Program Structure</a> for details)
          </p>
          <p>
            Measurement:<br>
            We present the time-frequency spectrograms of human voice input, piano melody input, and output audio, showed below. Comparing these three spectrograms, we can find out that...
          </p>
        </div>

        <div id="Auto-tuning">
          <h3>2. Auto-tuning</h3>
          <p>
            Vocal input:
            <a href="#" class="btn btn-default btn-sm" role="button" target="blank">
              <span class="glyphicon glyphicon-play"></span>
            </a>
            <br>
            Output of Auto-tuning:
            <a href="#" class="btn btn-default btn-sm" role="button" target="blank">
              <span class="glyphicon glyphicon-play"></span>
            </a>
          </p>

          <p>
            Explanation:<br>
            Tune Helper first performs pitch tracking on input vocal, extracting its time, frequency, amplitude and pitch information. It then uses these information to calculate the nearest note for each available frequency point of input vocal. If current point is off-key, Tune Helper performs a pitch shifting by phase vocoder, shifting pitch to the nearest music note. After the processing procedure, the output audio is an auto-tuned vocal.<br>
            (Check out <a href="#ProgramStructure">Program Structure</a> for details)
          </p>

          <p>
            Measurement of success:<br>
            We present the time-frequency spectrograms of both input audio and output audio, showed as follows. From these two spectrograms, it is easy to find out, that comparing to the input audio, the frequencies of auto-tuning output audio has been shifted to nearest notes, showing as "steps" in Figure 6.5.
          </p>
          
          <div class="row text-center">
              <img src="to-tune.png" style="height: 500px"><br>
              <p>Figure 6.4 Spectrogram of vocal input</p>
          </div>

          <div class="row text-center">
            <img src="tuned.png" style="height: 500px">
            <p>Figure 6.5 Spectrogram of auto-tuning output</p>
          </div>

        </div>
        
        <a href="#head-navbar">Back to top</a>
      </div>



      <div class="jumbotron" id="ProgramStructure">
        <h2>Program Structure</h2>
        <hr>
        <p>Tune Helper consists of two functions, <b>Auto-tuning</b>, and <b>Speech-to-sing</b>. The structure of these two functions are showed as follows.</p>

        <div class="row">
          <div class="col-sm-6 text-center">
            <h3>Auto-tuning</h3>
            <img src="auto-tuning.png">
            <br>
            <p>Figure 2.1</p>
          </div>

          <div class="col-sm-6 text-center">
            <h3>Speech-to-sing</h3>    
            <img src="speech-to-sing.png">
            <br>
            <p>Figure 2.2</p>
          </div>
        </div>
        <a href="#head-navbar">Back to top</a>
      </div>

      <div class="jumbotron" id="UserInterface">
        <h2>User Interface</h2>
        <hr>
        <p>The user interface of Tune Helper is written and built in MATLAB as well.</p>
        <div class="text-center">
          <img src="ui.png">
          <br>
          <p>Figure 3.1 Tune Helper user interface</p>
        </div>
        <a href="#head-navbar">Back to top</a>
      </div>

      <div class="jumbotron" id="Conclusion">
        <h2>Conclusion</h2>
        <hr>
        <p>
          In our project, we achieved both auto-tuning and speech-to-sing functions by using pitch tracking, beat tracking and phase vocoder. We use spectrograms to analyze and compare the result with input. We can get an ideal audio output by our program, Tune Helper.
        </p>
        <p>
          However, the quality of output audio is not very satisfying. The algorithm of tuning and pitch shifting should be improved in the future.
        </p>
        <a href="#head-navbar">Back to top</a>
      </div>

      <div class="jumbotron" id="RelatedWorks">
        <h2>Related Works</h2>
        <hr>
        <p>
          There are several existing software and papers that are related to our project, showed as follows.
        </p>

        <h3>Software: Auto-Tune</h3>
        <p>
          Wiki: <a href="http://en.wikipedia.org/wiki/Auto-Tune">http://en.wikipedia.org/wiki/Auto-Tune</a><br>
          Introduction: Auto-Tune is a software that used to create perfectly tuned vocals. It is based on the phase vocoder principle. Also, it is widely used in music industry.
        </p>

        <h3>Mobile App: Songify by Smule</h3>
        <p>
          iTunes App Storeï¼š<a href="https://itunes.apple.com/us/app/songify-by-smule/id438735719?mt=8">https://itunes.apple.com/us/app/songify-by-smule/id438735719?mt=8</a>
          <br>
          Introduction: Songify can automatically turn speech into music, creating the vocal effect that appears in the popular video "<a href="https://www.youtube.com/watch?v=tBb4cjjj1gI">AutoTune The News</a>" on YouTube.
        </p>

        <h3>Paper:</h3>
        <p>Check <a href="#References">references</a> for details.</p>
        <p>
          [1]. Middleton, Gareth. "Frequency Domain Pitch Correction." Connexions, December 17 (2003).<br>
          [2]. Laroche, Jean, and Mark Dolson. "Improved phase vocoder time-scale modification of audio." Speech and Audio Processing, IEEE Transactions on 7.3 (1999): 323-332.<br>
          [3]. Tyrangiel, Josh. "Auto-tune: Why pop music sounds perfect." Time Magazine (2009): 1877372-3.<br>
          [4]. Bello, Juan Pablo, Giuliano Monti, and Mark B. Sandler. "Techniques for Automatic Music Transcription." ISMIR. 2000.
        </p>

        <a href="#head-navbar">Back to top</a>
      </div>

      
    </div>
  	
  </body>

  <footer>
    <div class="container">
      <p class="text-center">&copy; 2015 Built by <a href="http://chenzhe-personal.appspot.com/">Zhe Chen</a></p>
    </div>
  </footer>

</html>